import hashlib
import json
import re
import time
from typing import Any

import requests


class PoizonSeller:
    SALT = "048a9c4943398714b356a696503d2d36"

    def __init__(self, dutoken: str, cookie: str):
        self.dutoken = dutoken
        self.cookie = cookie

        self.base_headers = {
            'accept': 'application/json',
            'accept-language': 'ko-KR,ko;q=0.9,zh-CN;q=0.8,zh;q=0.7,en-US;q=0.6,en;q=0.5',
            'channel': 'pc',
            'clientid': 'global',
            'content-type': 'application/json;charset=UTF-8',
            'language': 'ko',
            'origin': 'https://seller.poizon.com',
            'priority': 'u=1, i',
            'referer': 'https://seller.poizon.com/',
            'sec-ch-ua': '"Not(A:Brand";v="8", "Chromium";v="144", "Google Chrome";v="144"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"macOS"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-origin',
            'syscode': 'DU_USER_GLOBAL',
            'timezone': 'GMT+09:00',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36',
        }

    def update_credentials(self, dutoken: str = None, cookie: str = None):
        if dutoken is not None:
            self.dutoken = dutoken
        if cookie is not None:
            self.cookie = cookie

    def _get_headers(self):
        headers = self.base_headers.copy()
        headers['dutoken'] = self.dutoken
        headers['Cookie'] = self.cookie
        return headers

    def _generate_sign(self, payload_dict: dict[str, Any]) -> str:
        sorted_keys = sorted(payload_dict.keys())
        sign_str = ""
        for k in sorted_keys:
            val = payload_dict[k]
            if val is None:
                continue

            if isinstance(val, list):
                if not val:
                    sign_str += f"{k}"
                else:
                    sorted_list = sorted(
                        [json.dumps(x, separators=(',', ':')) if isinstance(x, (dict, list)) else str(x) for x in val])
                    sign_str += f"{k}{','.join(sorted_list)}"
            elif isinstance(val, dict):
                sign_str += f"{k}{json.dumps(val, separators=(',', ':'))}"
            else:
                if isinstance(val, bool):
                    sign_str += f"{k}{str(val).lower()}"
                else:
                    sign_str += f"{k}{val}"

        sign_str += self.SALT
        return hashlib.md5(sign_str.encode('utf-8')).hexdigest()

    def _send_request(self, url: str, payload_dict: dict[str, Any]) -> dict[str, Any]:
        sign = self._generate_sign(payload_dict)
        final_url = f"{url}?sign={sign}"

        payload_json = json.dumps(payload_dict, separators=(',', ':'))

        try:
            response = requests.post(final_url, headers=self._get_headers(), data=payload_json)
            response.raise_for_status()
            time.sleep(2)
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"Error sending request: {e}")
            return {}

    def search_product(self, keyword: str, page: int = 1, page_size: int = 20) -> dict[str, Any]:
        url = "https://seller.poizon.com/api/v1/h5/gw/intl-merchant-platform/oversea/aurora-spu/merchant/search"

        payload = {
            "pageNum": page,
            "identifyStatusEnable": True,
            "pageSize": page_size,
            "keyword": keyword,
            "current": page,
            "page": page
        }

        return self._send_request(url, payload)

    def find_matching_product(self, product_list: list[dict[str, Any]], search_keyword: str) -> dict[str, Any] | None:
        import difflib

        if not product_list or not search_keyword:
            return None

        def normalize(text: str) -> str:
            if not text:
                return ""
            return re.sub(r'[^a-z0-9]', '', str(text).lower())

        target_keyword = normalize(search_keyword)
        if not target_keyword:
            return None

        for product in product_list:
            article_number = product.get('articleNumber')
            if article_number and normalize(article_number) == target_keyword:
                return product

        if len(target_keyword) <= 4:
            return None

        best_match = None
        highest_score = 0.0
        THRESHOLD = 0.8

        for product in product_list:
            article_number = product.get('articleNumber')
            if not article_number:
                continue

            norm_article = normalize(article_number)
            score = difflib.SequenceMatcher(None, target_keyword, norm_article).ratio()

            if score >= THRESHOLD and score > highest_score:
                highest_score = score
                best_match = product

        return best_match

    def query_sale_now_info(self, spu_id: int) -> dict[str, Any]:
        """
        globalSpuIdë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆì˜ ìƒì„¸ íŒë§¤ ì •ë³´(ì‚¬ì´ì¦ˆë³„ ê°€ê²©, ì¬ê³  ë“±)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        Endpoint: /querySaleNowInfo
        """
        url = "https://seller.poizon.com/api/v1/h5/gw/adapter/pc/bidding/query/querySaleNowInfo"

        payload = {
            "source": "PC",
            "spuId": spu_id
        }

        return self._send_request(url, payload)

    def extract_price_info(self, api_response: dict[str, Any]) -> dict[str, Any]:
        """
        API ì‘ë‹µ(query_sale_now_info)ì—ì„œ ì‚¬ì´ì¦ˆë³„ ê°€ê²© ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.
        í•œêµ­ ë…¸ì¶œê°€(SALE_LOCAL_POIZON_LEAK)ì™€ ì¤‘êµ­ ë…¸ì¶œê°€(CN_LEAK) ì¤‘ ë” ë‚®ì€ ê°€ê²©ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        data = api_response.get('data', {})
        if not data:
            return {}

        # ê¸°ë³¸ ìƒí’ˆ ì •ë³´
        summary = {
            "productTitle": data.get("skuInfos", [{}])[0].get("productName", ""),
            "articleNumber": data.get("articleNumber", ""),
            "imageUrl": data.get("logoUrl", ""),
            "sizeList": []
        }

        # SKU(ì‚¬ì´ì¦ˆ)ë³„ ìˆœíšŒ
        sku_infos = data.get("skuInfos", [])
        for sku in sku_infos:
            # SPU(í—¤ë” ì •ë³´)ëŠ” ê±´ë„ˆëœ€
            if sku.get("productType") == "SPU":
                continue

            # ì‚¬ì´ì¦ˆ ëª… ì¶”ì¶œ (ì˜ˆ: "ë¸”ë™*#*XS" -> "XS")
            raw_desc = sku.get("propertyDesc", "")
            size_name = raw_desc.split("*#*")[-1] if "*#*" in raw_desc else raw_desc

            # ê°€ê²© ì •ë³´ ì´ˆê¸°í™”
            kr_price = None  # í•œêµ­ ë…¸ì¶œê°€
            cn_price = None  # ì¤‘êµ­ ë…¸ì¶œê°€

            # salesVolumeGroups í™•ì¸ (ë³´í†µ buttonCode: 0 ì´ ì¼ë°˜ íŒë§¤)
            groups = sku.get("salesVolumeGroups", [])
            for group in groups:
                # groupId '30'(30ì¼ ê¸°ì¤€) ë˜ëŠ” '7' ë“± ë¡œì§ì— ë”°ë¼ ì„ íƒ.
                # ì—¬ê¸°ì„œëŠ” buttonCode 0(ì¼ë°˜ ì…ì°°)ì¸ ë°ì´í„°ë§Œ í™•ì¸
                if group.get("buttonCode") != 0:
                    continue

                infos = group.get("salesVolumeInfos", [])
                for info in infos:
                    area_id = info.get("areaId")
                    price_obj = info.get("price", {})

                    # ê°€ê²©ì´ ì—†ëŠ” ê²½ìš°(None) ê±´ë„ˆëœ€
                    if not price_obj:
                        continue

                    amount = int(price_obj.get("money", {}).get("amount", 0))
                    if amount == 0:
                        continue

                    # í•œêµ­ ë…¸ì¶œ ê°€ëŠ¥ ê°€ê²©
                    if area_id == "SALE_LOCAL_POIZON_LEAK":
                        kr_price = amount
                    # ì¤‘êµ­ ë…¸ì¶œ ê°€ëŠ¥ ê°€ê²©
                    elif area_id == "CN_LEAK":
                        cn_price = amount

            # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ê°€ê²©ì´ ìˆìœ¼ë©´ ë…¸ì¶œ
            if kr_price or cn_price:
                # ë¹„êµë¥¼ ìœ„í•´ ì—†ëŠ” ê°€ê²©ì€ ë¬´í•œëŒ€ ì²˜ë¦¬
                comp_kr = kr_price if kr_price else float('inf')
                comp_cn = cn_price if cn_price else float('inf')

                # ìµœì  ë…¸ì¶œê°€ (ë” ë‚®ì€ ê°€ê²©)
                target_price = min(comp_kr, comp_cn)

                summary["sizeList"].append({
                    "size": size_name,
                    "krPrice": kr_price if kr_price else 0,  # 0ì´ë©´ ê°€ê²© ì—†ìŒ
                    "cnPrice": cn_price if cn_price else 0,  # 0ì´ë©´ ê°€ê²© ì—†ìŒ
                    "targetPrice": target_price,  # ì‹¤ì œ ì…ë ¥í•´ì•¼ í•  ê°€ê²©
                    "isCheaperIn": "CN" if comp_cn < comp_kr else "KR"  # ì–´ë””ê°€ ë” ì‹¼ì§€
                })

        return summary

    def query_product_detail_analytics(self, spu_id: int) -> dict[str, Any]:
        """
        ìƒí’ˆì˜ ìƒì„¸ ë¶„ì„ ë°ì´í„°(íŒë§¤ ì¶”ì„¸, ì£¼ë¬¸ ê¸°ë¡ ë“±)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        Endpoint: /getMoreFloatingLayer
        """
        url = "https://seller.poizon.com/api/v1/h5/gw/intl-price-center/merchant/price/floatLayer/getMoreFloatingLayer"

        payload = {
            "spuId": spu_id,
            "source": 0,
            "timeRangeTypeCode": 0,
            "platformFlag": "PC"
        }

        return self._send_request(url, payload)

    def analyze_product_performance(self, analytics_response: dict[str, Any]) -> dict[str, Any]:
        """
        ìƒì„¸ ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒí’ˆì˜ íŒë§¤ ì„±ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        - ê±°ë˜ ì¶”ì„¸(Trend): ì¼ë³„ ê±°ë˜ëŸ‰ ë° ê°€ê²© ì¶”ì´
        - ìµœê·¼ ì£¼ë¬¸(Record): ìµœê·¼ ì²´ê²°ëœ ì£¼ë¬¸ì˜ ì‹œê°„, ê°€ê²©, ì‚¬ì´ì¦ˆ
        """
        data = analytics_response.get('data', {})
        if not data:
            return {"status": "No Data"}

        result = {
            "status": "Success",
            "trend_summary": {},
            "recent_orders": [],
            "last_sold_time": None
        }

        # 1. íŒë§¤ ì¶”ì„¸ ë¶„ì„ (historyTradeTrend)
        trend_data = data.get('historyTradeTrend', {}).get('overseaBiddingTradeTrendDTO', {})
        dates = trend_data.get('horizontals', [])
        prices = trend_data.get('verticals', [])

        if dates:
            result['trend_summary'] = {
                "period": f"{dates[0]} ~ {dates[-1]}",
                "data_points": len(dates),  # ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ë‚ ì§œ ìˆ˜ (ê±°ë˜ í™œë°œë„ ì§€í‘œ)
                "avg_price_trend": prices[-5:] if prices else [],  # ìµœê·¼ 5ì¼ê°„ ê°€ê²© íë¦„
                "last_price": prices[-1] if prices else 0
            }

        # 2. ìµœê·¼ ì£¼ë¬¸ ê¸°ë¡ ë¶„ì„ (historyTradeRecord)
        record_data = data.get('historyTradeRecord', {}).get('tradeRecordDTO', {})
        trade_records = record_data.get('tradeRecords', [])

        for trade in trade_records[:10]:  # ìµœê·¼ 10ê±´ë§Œ ì¶”ì¶œ
            price_info = trade.get('price', {})
            amount = price_info.get('amountText', 'N/A')

            result['recent_orders'].append({
                "time": trade.get('time'),  # ì˜ˆ: "3ì‹œê°„ ì „"
                "size": trade.get('size'),  # ì˜ˆ: "XL, Black"
                "price": amount,  # ì˜ˆ: "90,000"
                "region": trade.get('address')  # ì˜ˆ: "Asia"
            })

        # ê°€ì¥ ìµœê·¼ íŒë§¤ ì‹œê°„ ì¶”ì¶œ
        if result['recent_orders']:
            result['last_sold_time'] = result['recent_orders'][0]['time']

        return result

    def _parse_minutes_ago(self, time_str: str) -> int:
        """
        [ë‚´ë¶€ í—¬í¼] '3ì‹œê°„ ì „', '1ì¼ ì „' í…ìŠ¤íŠ¸ë¥¼ 'ë¶„(Minute)' ë‹¨ìœ„ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        s = time_str.replace(" ", "").strip()

        # 1. ë°©ê¸ˆ/ë¶„ ì „ ì²˜ë¦¬
        if "ë°©ê¸ˆ" in s:
            return 0
        if "ë¶„ì „" in s:
            try:
                mins = int(re.search(r'(\d+)', s).group(1))
                return mins
            except:
                return 1

        # 2. ì‹œê°„ ì „ ì²˜ë¦¬
        if "ì‹œê°„ì „" in s:
            try:
                hours = int(re.search(r'(\d+)', s).group(1))
                return hours * 60
            except:
                return 60

        # 3. ì¼/ì£¼/ë‹¬/ë…„ ì²˜ë¦¬
        days = 0
        try:
            num = int(re.search(r'(\d+)', s).group(1))
            if "ì¼ì „" in s:
                days = num
            elif "ì£¼ì „" in s:
                days = num * 7
            elif "ë‹¬ì „" in s:
                days = num * 30
            elif "ë…„ì „" in s:
                days = num * 365
        except:
            pass

        # ê¸°ë³¸ì ìœ¼ë¡œ 1ì¼ ì´ìƒì´ë©´ ë¶„ìœ¼ë¡œ í™˜ì‚° (ìµœì†Œ 1440ë¶„)
        if days > 0:
            return days * 24 * 60

        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•„ì£¼ ì˜¤ë˜ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ (ìµœí•˜ì )
        return 999999

    def calculate_sales_velocity(self, analytics_response: dict[str, Any]) -> dict[str, Any]:
        """
        [ì •ë°€ ë¶„ì„] íŒë§¤ ì†ë„(Velocity)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì ìˆ˜ê°€ ê¸‰ê²©íˆ ë–¨ì–´ì§€ëŠ” 'ê°ì‡  ëª¨ë¸'ì„ ì‚¬ìš©í•˜ì—¬
        'ì§€ê¸ˆ ë‹¹ì¥' ì˜ íŒ”ë¦¬ëŠ” ìƒí’ˆì„ í™•ì‹¤í•˜ê²Œ êµ¬ë¶„í•©ë‹ˆë‹¤.
        """
        data = analytics_response.get('data', {})
        trade_records = data.get('historyTradeRecord', {}).get('tradeRecordDTO', {}).get('tradeRecords', [])

        total_velocity_score = 0.0
        details = []

        # ê°€ì¤‘ì¹˜ ìƒìˆ˜ (ì ìˆ˜ ìŠ¤ì¼€ì¼ ì¡°ì ˆìš©)
        BASE_POINT = 10000

        for trade in trade_records:
            time_str = trade.get('time', '')

            # 1. íŒë§¤ëœ ì§€ ëª‡ ë¶„ ì§€ë‚¬ëŠ”ì§€ ê³„ì‚°
            elapsed_mins = self._parse_minutes_ago(time_str)

            # 2. ê°ì‡  ê³µì‹ ì ìš©: ì ìˆ˜ = 10000 / (ê²½ê³¼ë¶„ + 5)
            # ë¶„ëª¨ì— 5ë¥¼ ë”í•˜ëŠ” ì´ìœ ëŠ” 0ë¶„ì¼ ë•Œ ë¬´í•œëŒ€ë¥¼ ë°©ì§€í•˜ê³  ê³¡ì„ ì„ ì™„ë§Œí•˜ê²Œ í•˜ê¸° ìœ„í•¨
            score = BASE_POINT / (elapsed_mins + 5)

            total_velocity_score += score

            details.append({
                "time_str": time_str,
                "elapsed_mins": elapsed_mins,
                "score": round(score, 2)
            })

        # ë“±ê¸‰ ì‚°ì • (20ê°œ ë°ì´í„° ê¸°ì¤€ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼)
        velocity_rank = "F (ì •ì²´)"
        if total_velocity_score >= 5000:
            velocity_rank = "SSS (ë¯¸ì¹œ ì†ë„ ğŸ”¥)"  # ë°©ê¸ˆ~1ì‹œê°„ ì´ë‚´ ë‹¤ìˆ˜
        elif total_velocity_score >= 2000:
            velocity_rank = "S (í­ë°œì )"  # 1~3ì‹œê°„ ì´ë‚´ ë‹¤ìˆ˜
        elif total_velocity_score >= 500:
            velocity_rank = "A (ë§¤ìš° ë¹ ë¦„)"  # í•˜ë£¨ ì´ë‚´ ë‹¤ìˆ˜
        elif total_velocity_score >= 100:
            velocity_rank = "B (ì–‘í˜¸)"  # 2~3ì¼ ì´ë‚´ ë‹¤ìˆ˜
        elif total_velocity_score >= 20:
            velocity_rank = "C (ë³´í†µ)"

        return {
            "velocity_score": round(total_velocity_score, 2),
            "rank": velocity_rank,
            "details": details
        }

    def query_bidding_info(self, global_spu_id: int) -> dict[str, Any]:
        """
        ì…ì°°(Bidding)ì— í•„ìš”í•œ SKU IDì™€ ì‚¬ì´ì¦ˆ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        Endpoint: /batchQueryNewBidding
        """
        url = "https://seller.poizon.com/api/v1/h5/gw/adapter/pc/bidding/query/batchQueryNewBidding"

        payload = {
            "biddingType": -1,
            "globalSpuIds": [global_spu_id],  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì„ì— ì£¼ì˜
            "autoFillFulfillmentBiddingType": 1,
            "needShowSizeKey": True
        }

        return self._send_request(url, payload)

    def extract_sku_size_info(self, bidding_response: dict[str, Any]) -> list[dict[str, Any]]:
        """
        ì…ì°° ì •ë³´ì—ì„œ SKU IDì™€ ì‚¬ì´ì¦ˆ(KR, EU ë“±) ì •ë³´ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        [ìˆ˜ì •] ì˜ë¥˜ ì‚¬ì´ì¦ˆ(XS, M, L ë“±)ì˜ 'SIZE' í‚¤ë„ ì¸ì‹í•˜ì—¬ KR/EU í•„ë“œì— í˜¸í™˜ë˜ë„ë¡ ë§¤í•‘í•©ë‹ˆë‹¤.
        """
        data = bidding_response.get('data', [])
        if not data:
            return []

        # dataëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ë©° ë³´í†µ 1ê°œì˜ ìƒí’ˆ ì •ë³´ê°€ ë“¤ì–´ì˜´
        product_data = data[0]
        sku_list = product_data.get('skuInventoryInfoList', [])

        extracted_skus = []

        for sku in sku_list:
            sku_id = sku.get('skuId')
            raw_prop = sku.get('spuPropNew', '')  # ì˜ˆ: "í™”ì´íŠ¸-ë¸”ë£¨ KR 250" ë˜ëŠ” "íˆ¬ëª… í•‘í¬ SIZE 2XS"

            # 1. ê¸°ë³¸ ì‚¬ì´ì¦ˆ ì¶”ì¶œ (ë¬¸ìì—´ì˜ ë§ˆì§€ë§‰ ë‹¨ì–´ë¥¼ ì‚¬ì´ì¦ˆë¡œ ê°„ì£¼)
            # ì˜ˆ: "SIZE 2XS" -> "2XS", "KR 250" -> "250"
            # ìŠ¤í™ ì •ë³´ê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ê°’
            fallback_size = raw_prop.split(' ')[-1] if ' ' in raw_prop else raw_prop

            sku_info = {
                "skuId": sku_id,
                "raw_prop": raw_prop,
                "size_kr": "N/A",
                "size_eu": "N/A",
                "size_us": "N/A"
            }

            # 2. ìƒì„¸ ìŠ¤í™ì—ì„œ ì •í™•í•œ í‚¤ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì´ì¦ˆ ì¶”ì¶œ
            specs = sku.get('skuPropAllSpecification', [])

            for spec in specs:
                key = spec.get('sizeKey')
                val_str = spec.get('skuProp', '')

                # ê°’ì—ì„œ ì‚¬ì´ì¦ˆë§Œ ì¶”ì¶œ (ë§ˆì§€ë§‰ ë‹¨ì–´)
                size_val = val_str.split(' ')[-1] if ' ' in val_str else val_str

                if key == 'KR':
                    sku_info['size_kr'] = size_val
                elif key == 'EU':
                    sku_info['size_eu'] = size_val
                elif key == 'US Men':
                    sku_info['size_us'] = size_val
                # [ì¶”ê°€ëœ ë¶€ë¶„] ì˜ë¥˜ë‚˜ ê¸°íƒ€ ì¡í™”ì˜ ì¼ë°˜ ì‚¬ì´ì¦ˆ í‚¤ ì²˜ë¦¬
                elif key == 'SIZE' or key == 'Numeric Size':
                    # KR/EU ì¹¸ì´ ë¹„ì–´ìˆë‹¤ë©´ ì´ ê°’ì„ ì±„ì›Œë„£ì–´ ì‹ë³„ ê°€ëŠ¥í•˜ê²Œ í•¨
                    if sku_info['size_kr'] == "N/A":
                        sku_info['size_kr'] = size_val
                    if sku_info['size_eu'] == "N/A":
                        sku_info['size_eu'] = size_val

            # 3. ì—¬ì „íˆ N/Aë¼ë©´ raw_propì—ì„œ ì¶”ì¶œí•œ ê¸°ë³¸ê°’ ì‚¬ìš© (ì•ˆì „ì¥ì¹˜)
            if sku_info['size_kr'] == "N/A":
                sku_info['size_kr'] = fallback_size
            if sku_info['size_eu'] == "N/A":
                sku_info['size_eu'] = fallback_size

            extracted_skus.append(sku_info)

        return extracted_skus

    def get_product_info(self, model_number: str) -> dict[str, Any] | None:
        """
        [í†µí•© ë©”ì†Œë“œ] ëª¨ë¸ëª…ì„ ì…ë ¥ë°›ì•„ ìƒí’ˆì˜ ì¢…í•© ì •ë³´(ê¸°ë³¸ì •ë³´, íŒë§¤ì ìˆ˜, ê°€ê²©, SKU)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ê°€ê²© ë§¤ì¹­ ì‹œ KR/EU/US ë“± ë‹¤ì–‘í•œ ì‚¬ì´ì¦ˆ í‘œê¸°ë¥¼ êµì°¨ ê²€ì¦í•©ë‹ˆë‹¤.
        """
        # 1. ìƒí’ˆ ê²€ìƒ‰
        print(f"[Info] '{model_number}' ê²€ìƒ‰ ì‹œì‘...")
        search_res = self.search_product(model_number)
        if search_res.get('code') != 200:
            print(f"[Error] ê²€ìƒ‰ API ì˜¤ë¥˜: {search_res.get('msg')}")
            return None

        # 2. ì •í™•í•œ ìƒí’ˆ ë§¤ì¹­
        product_list = search_res.get('data', {}).get('merchantSpuDtoList', [])
        matched_product = self.find_matching_product(product_list, model_number)

        if not matched_product:
            print(f"[Info] '{model_number}'ì— í•´ë‹¹í•˜ëŠ” ì •í™•í•œ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        global_spu_id = matched_product.get('globalSpuId')
        article_number = matched_product.get('articleNumber')
        title = matched_product.get('title')

        print(f"[Info] ìƒí’ˆ ë§¤ì¹­ ì„±ê³µ: {title} (GID: {global_spu_id})")

        # 3. íŒë§¤ ì†ë„(Velocity) ì ìˆ˜ ë¶„ì„
        analytics_res = self.query_product_detail_analytics(global_spu_id)
        velocity_data = self.calculate_sales_velocity(analytics_res)

        # 4. í˜„ì¬ íŒë§¤ê°€ ë° ìµœì  ë…¸ì¶œê°€ ë¶„ì„
        sale_now_res = self.query_sale_now_info(global_spu_id)
        price_data = self.extract_price_info(sale_now_res)

        # 5. ì…ì°°ìš© SKU ë° ì‚¬ì´ì¦ˆ ì •ë³´ ì¡°íšŒ
        bidding_res = self.query_bidding_info(global_spu_id)
        sku_data = self.extract_sku_size_info(bidding_res)

        # 6. ë°ì´í„° ë³‘í•© (ê°œì„ ëœ ë§¤ì¹­ ë¡œì§)
        # price_dataì˜ sizeListë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (Key: ì‚¬ì´ì¦ˆëª… ë¬¸ìì—´)
        price_map = {str(item['size']).strip(): item for item in price_data.get('sizeList', [])}

        merged_sizes = []
        for sku in sku_data:
            matched_price = {}

            # [í•µì‹¬ ìˆ˜ì •] ë§¤ì¹­ í™•ë¥ ì„ ë†’ì´ê¸° ìœ„í•´ ì—¬ëŸ¬ í‚¤(KR, EU, US, Raw)ë¡œ ì‹œë„
            # Adidas ê°™ì€ ê²½ìš° price_map í‚¤ê°€ '36'(EU)ì¼ ìˆ˜ ìˆê³ , sku['size_kr']ì€ '220'ì¼ ìˆ˜ ìˆìŒ
            keys_to_try = [
                str(sku.get('size_kr', '')).strip(),  # 1ìˆœìœ„: KR
                str(sku.get('size_eu', '')).strip(),  # 2ìˆœìœ„: EU (ì—¬ê¸°ì„œ ì£¼ë¡œ ë§¤ì¹­ë¨)
                str(sku.get('size_us', '')).strip(),  # 3ìˆœìœ„: US
                str(sku.get('raw_prop', '')).split(' ')[-1].strip()  # 4ìˆœìœ„: ì›ë³¸ ë¬¸ìì—´ì˜ ë§ˆì§€ë§‰ ë‹¨ì–´
            ]

            for key in keys_to_try:
                if key and key in price_map:
                    matched_price = price_map[key]
                    break

            merged_sizes.append({
                "size_kr": sku['size_kr'],
                "size_eu": sku['size_eu'],
                "size_us": sku['size_us'],
                "sku_id": sku['skuId'],
                # ë§¤ì¹­ëœ ê°€ê²© ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0
                "target_price": matched_price.get('targetPrice', 0),
                "kr_leak_price": matched_price.get('krPrice', 0),
                "cn_leak_price": matched_price.get('cnPrice', 0),
                "is_cheaper_in": matched_price.get('isCheaperIn', 'N/A')
            })

        # 7. ìµœì¢… ê²°ê³¼ êµ¬ì„±
        final_result = {
            "model_info": {
                "article_number": article_number,
                "title": title,
                "global_spu_id": global_spu_id,
                "image_url": matched_product.get('logoUrl')
            },
            "sales_score": {
                "velocity_score": velocity_data.get('velocity_score', 0),
                "rank": velocity_data.get('rank', 'F'),
                "recent_sales_count": len(velocity_data.get('details', []))
            },
            "sizes": merged_sizes
        }

        return final_result


if __name__ == '__main__':
    dutoken = 'jFgarJUNT_N9WO0iYG90H7rbjdabJ19ivUZKllBq912xBxogFpDCyqjP6zkjQAbGbxnn90JqsHwkRgGIwcTjBp_NLtUWxZn3P3hib0W3Ay4fzq2Quw4jjcWEM1B5KjkHQAwl3pN4mJvlTHWCUyclzzAIMdkUHV9O17AQxfmZ+BWTsWNhrFmniJ6rsw4uGbYNBgsgeKnVh4xFSp4xkqI+aQcWQNr7CbfkxdkA10zVfFHc20aqXB8YQ+dmSwAOacvvtAMEf7xHc1z8eadvYgPkYqzeipDGcXHKHYCTYRIvVsW6gndMI5sIr5K53N4mCnqr8+EMe9uedMwCbOk8UTbvvS5dqeqIYkS6wpSmqURmGVeU9uU06G1W4sfbWbVFsZBGx2m7xOZjPG51gPM-'
    cookie = 'fe_sensors_ssid=32754331-51d1-49ab-931d-696fc45faaeb; _scid=OOd_8W0Y2ZnY0ZJQW_gILyv8O3ROGi_J; _fbp=fb.1.1768801174503.137637527949170360; _ga=GA1.1.1154156648.1768801175; _ScCbts=%5B%5D; _sctr=1%7C1768748400000; language=en; _gcl_au=1.1.760710505.1768801200; _tt_enable_cookie=1; _ttp=01KFAC8SRAEXS35PS6C7BFKK5R_.tt.1; sk=9TxXGIYI4UbnzgP0deih9puTDVEgtJT1SXlAjmaqvUrqzHILKEPzINFAOmlSaLttXw2csLZtRlySYmlJtUrw5GNB6T21; _ee_channel=; _ee_platform=pc; _ee_channel_data=; boundToken=; uid=1000534072; accessToken=2yftJGwXmvE46loAni3GQYGzdqvT3I58qcCHIY43gkjTz43DAf1pRBbAbBZj1Yvm; tfstk=gBAs3zVwKndF8F3tDluUAwX2NnCX12lrGr_vrEFak1C9cEKyYtIV_dkvcHse_G8N6iFXrUC2QdY4Spxyy5RZIsPfssfx40lraRYGis3di-jbS6QfzRh46SLdsZkZCNwtaFYgJqVdPSlrGIaiONIvDOBL9aIL6NFvDkQdxZbYXZFtReIhvZQAXSQLvNb7BPKAM2TdxZCADnBtReIhksIxOzZCuA_v54WSZopaZpTOASFv6AX5VmIh-ZOC5OsRpOPv5B_1CgL9wD95oZ9JNOx-YRS9FCt5zhlL13T9enpJvXP1GepJG6dKvyS9EeOf_C3q66LJdUW610NNmhtMsB67kcKXvUvl6Cn0_GvvJIIe6qPf2L8lOwAqx5IXpKdNIsqtfsLCkg5zagGJz-aCES_C42gQn-Au55Eqw27ymOQhWbuIRkwcBwbBK2gQn-XO-NCjR2ZQn; feLoginExpire=1769422329000; feLoginss=1000534072; ttcsid_D38MK7RC77U5QJRHURB0=1768817574260::N0CaK6K5INyafPlweXUd.3.1768817623225.1; ttcsid=1768817574260::2T4byYqkSKQgazlZPrYB.3.1768817623225.0; duToken=jFgarJUNT_N9WO0iYG90H7rbjdabJ19ivUZKllBq912xBxogFpDCyqjP6zkjQAbGbxnn90JqsHwkRgGIwcTjBp_NLtUWxZn3P3hib0W3Ay4fzq2Quw4jjcWEM1B5KjkHQAwl3pN4mJvlTHWCUyclzzAIMdkUHV9O17AQxfmZ+BWTsWNhrFmniJ6rsw4uGbYNBgsgeKnVh4xFSp4xkqI+aQcWQNr7CbfkxdkA10zVfFHc20aqXB8YQ+dmSwAOacvvtAMEf7xHc1z8eadvYgPkYqzeipDGcXHKHYCTYRIvVsW6gndMI5sIr5K53N4mCnqr8+EMe9uedMwCbOk8UTbvvS5dqeqIYkS6wpSmqURmGVeU9uU06G1W4sfbWbVFsZBGx2m7xOZjPG51gPM-; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2219bd4c078b961-0eb9586c70a76f8-1b525631-3686400-19bd4c078bad15%22%2C%22first_id%22%3A%22%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E4%BB%98%E8%B4%B9%E5%B9%BF%E5%91%8A%E6%B5%81%E9%87%8F%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC%22%2C%22%24latest_referrer%22%3A%22https%3A%2F%2Fwww.google.com%2F%22%2C%22%24latest_utm_source%22%3A%22seo%22%7D%2C%22identities%22%3A%22eyIkaWRlbnRpdHlfY29va2llX2lkIjoiMTliZDRjMDc4Yjk2MS0wZWI5NTg2YzcwYTc2ZjgtMWI1MjU2MzEtMzY4NjQwMC0xOWJkNGMwNzhiYWQxNSJ9%22%2C%22history_login_id%22%3A%7B%22name%22%3A%22%22%2C%22value%22%3A%22%22%7D%2C%22%24device_id%22%3A%2219bd4c078b961-0eb9586c70a76f8-1b525631-3686400-19bd4c078bad15%22%7D; _scid_r=NWd_8W0Y2ZnY0ZJQW_gILyv8O3ROGi_JFuAVcQ; _ga_9YMHX0NL8P=GS2.1.s1768831135$o3$g1$t1768834331$j60$l0$h0; _ee_timestamp=1768834902911; forterToken=4b29072455274d96b14fc8ea06c64e3a_1768834260101__UDF43-mnf-a4_24ck_'
